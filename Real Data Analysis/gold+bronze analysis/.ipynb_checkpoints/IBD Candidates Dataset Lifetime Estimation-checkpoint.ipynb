{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaec4ced-a060-4a90-8dd5-8091ba0adcca",
   "metadata": {},
   "source": [
    "# Notebook Dedicated to Estimate the Lifetime of the IBD Candidates Real Dataset and compute the Total Cut Time due to HS and ATM events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9873a86a-ff6d-4ecf-ae6a-66a491d4ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5830e-b4fd-4ec2-876f-9b8de3547692",
   "metadata": {},
   "source": [
    "# Load the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc95c2-d144-41c6-a4b2-7a995cff7ea1",
   "metadata": {},
   "source": [
    "## RUN Lifetime txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab503ad-6a4d-49a3-a362-1ee14835c530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dir = 'E:/Data/antinu/antinu_realdata/runID_list_time.txt'\n",
    "\n",
    "runID, time1, time2 = [], [], []\n",
    "\n",
    "with open(file_dir, \"r\", encoding=\"utf-8\") as f:\n",
    "    for linea in f:\n",
    "        if linea.strip():  # Evitar líneas vacías\n",
    "            valores = linea.split()  # Separa por espacios o tabulaciones\n",
    "            runID.append(int(valores[0]))\n",
    "            time1.append(float(valores[1]))\n",
    "            time2.append(float(valores[2]))\n",
    "            \n",
    "runID_lt = np.array(runID)\n",
    "time1_lt = np.array(time1) # RAW LIVETIME (DAYS)\n",
    "time2_lt = np.array(time2) # NET LIVETIME (DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f101d866-85ae-4c82-b070-e10066e17030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300000, 300001, 300002, ..., 310635, 310636, 310637])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4046a2-2571-4759-b733-ac178bf1d4e1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d687aa-dfc5-4b8f-9dcf-5a41c084b715",
   "metadata": {},
   "source": [
    "### Define the Cuts Used to Obtain the Loaded Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b458a210-5536-4a39-87f7-bb42625f1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of Primary cuts =====================================================\n",
    "dcFlag_cut = 0x2100000042C2\n",
    "nhits_cut = 20\n",
    "\n",
    "en_cut_inf = 1.6\n",
    "en_cut_sup = 8.0\n",
    "posr_cut_sup = 5500\n",
    "runID_cut = 300700\n",
    "\n",
    "#Vetoing HS and atmospheric :\n",
    "nhits_hs_number = 1500  #nhits above this value is an hotspot suspected\n",
    "nhits_atm_number = 3000 #nhits above this value is an atmospheric suspected\n",
    "dt_hs_remove = 1e6  # Remove 1s of data after a hs\n",
    "dt_atm_remove = 20*1e6  # Remove 20s of data after an atmospheric\n",
    "\n",
    "#Antinufinder cuts ===============================================================\n",
    "alpha = 9\n",
    "tau = 215\n",
    "dt_sup_lim = 1000\n",
    "dt_inf_lim = 0.5 # (0.5) -> To avoid retriggers\n",
    "\n",
    "dr_sup_lim = 1000 \n",
    "dr_inf_lim = 0\n",
    "\n",
    "energy_delay_sup_cut = 2.3\n",
    "energy_delay_inf_cut = 1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9914b3-c0fe-4c42-9b63-daf460cf128f",
   "metadata": {},
   "source": [
    "### Load Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dced69a-8b4b-4365-adf8-e5187ef9e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories where the dictonaries were saved and pattern filename\n",
    "antinu_dict_bronze_dir = 'C:/Users/joanc/jupyter notebooks/Antineutrino Analysis/Real Data Analysis/bronze analysis/antinu_dict/vetoing plus runID cut/'\n",
    "antinu_dict_gold_dir = 'C:/Users/joanc/jupyter notebooks/Antineutrino Analysis/Real Data Analysis/gold analysis/antinu_dict/vetoing plus runID cut/'\n",
    "\n",
    "#Read Analysis and AnalysisR dictionaries\n",
    "fname = f'antinu*_dict_delta_t_{dt_inf_lim}_{dt_sup_lim}(mcs)_dr_{dr_inf_lim}_{dr_sup_lim}(mm)_en_{en_cut_inf}_{en_cut_sup}(MeV)_R_{posr_cut_sup}(mm)_en_delay_{energy_delay_inf_cut}_{energy_delay_sup_cut}(MeV)'\n",
    "\n",
    "#Create lists with the bronze and gold dictionaries\n",
    "antinu_bronze_flist = glob.glob(antinu_dict_bronze_dir + fname +'.pkl')\n",
    "antinu_gold_flist = glob.glob(antinu_dict_gold_dir + fname +'.pkl')\n",
    "\n",
    "#Concatenate list of bronze and gold data\n",
    "flist = list(itertools.chain(antinu_bronze_flist, antinu_gold_flist))\n",
    "\n",
    "#data to extract:\n",
    "energy_prompt_real_data = np.array([])\n",
    "energy_delay_real_data = np.array([])\n",
    "delta_t_real_data = np.array([])\n",
    "delta_r_real_data = np.array([])\n",
    "hs_counts = np.array([])\n",
    "atm_counts = np.array([])\n",
    "runID_real_data = np.array([])\n",
    "\n",
    "# Load data and save observables\n",
    "for i_dx, file_i in enumerate(flist):\n",
    "    with open(file_i, 'rb') as f:\n",
    "        #locals()['antinu_dict_' + str(i_dx)] = pickle.load(f)\n",
    "        antinu_dict_i = pickle.load(f)\n",
    "\n",
    "    energy_prompt_real_data = np.append(energy_prompt_real_data, antinu_dict_i['energy_prompt'])\n",
    "    energy_delay_real_data = np.append(energy_delay_real_data, antinu_dict_i['energy_delay'])\n",
    "    delta_t_real_data = np.append(delta_t_real_data, antinu_dict_i['delta_t'])\n",
    "    delta_r_real_data = np.append(delta_r_real_data, antinu_dict_i['delta_r'])\n",
    "    hs_counts = np.append(hs_counts, antinu_dict_i['hs_counter'])\n",
    "    atm_counts = np.append(atm_counts, antinu_dict_i['atm_counter'])\n",
    "    runID_real_data = np.append(runID_real_data, antinu_dict_i['runID'])\n",
    "\n",
    "runID_real_data = np.unique(runID_real_data)\n",
    "hs_total_counts = np.sum(hs_counts)\n",
    "atm_total_counts = np.sum(atm_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e130d74-dcd4-4232-bec6-e6ec8057cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300001., 301116., 301807., 302251., 302379., 302983., 303025.,\n",
       "       303565., 303788., 304598., 304664., 304672., 304709., 304896.,\n",
       "       305079., 305298., 306046., 306832., 307001., 307917., 308140.,\n",
       "       308362., 308417., 308589., 308910., 309080., 309799., 309900.,\n",
       "       310455., 310457., 310578.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runID_real_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea035b-40dd-4020-8a49-290964b76594",
   "metadata": {},
   "source": [
    "# Compute Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "684e6b20-afcf-4adc-84af-c0deed307350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Lifetime of the IBD candidates dataset is 1.27 days\n",
      "Removed 29.44 days due to hotspots and atmospherics\n"
     ]
    }
   ],
   "source": [
    "#Check where the runID in data are present in the runID lifetime list\n",
    "same_runID_condition = np.in1d(runID_lt, runID_real_data)\n",
    "\n",
    "#Extract the time of runs that verify the same_runID_condition\n",
    "lt_list = time2_lt[same_runID_condition]\n",
    "#Compute the total duration of the selected runs\n",
    "total_lt_days = np.sum(lt_list)\n",
    "\n",
    "#Time removed by cuts on Hotspots and Atmospherics\n",
    "mcs_to_days_conv = (10**(-6))/(24*60*60)\n",
    "hotspots_time = hs_total_counts * dt_hs_remove * mcs_to_days_conv\n",
    "atm_time = hs_total_counts * dt_atm_remove * mcs_to_days_conv\n",
    "\n",
    "total_cut_days = hotspots_time + atm_time\n",
    "\n",
    "print(f'Total Lifetime of the IBD candidates dataset is {total_lt_days:.2f} days')\n",
    "print(f'Removed {total_cut_days:.2f} days due to hotspots and atmospherics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
